{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMrjQo3JD40i",
        "outputId": "d3c37455-f154-4ffa-d7e0-9a4a5f847090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 0 B/3,626 B 0%] [Connected to r2u.stat.i\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)]\u001b[0m\r                                                                                                    \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)]\u001b[0m\r                                                                                                    \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcon\u001b[0m\r                                                                                                    \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [Waiting for headers] [4 InRelease 14.2 kB/129 kB 11%] [Waiting for headers] [Connected to ppa.la\u001b[0m\r                                                                                                    \rGet:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [59.5 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,107 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,446 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,610 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,163 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,391 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,452 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,319 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,672 kB]\n",
            "Fetched 23.6 MB in 6s (3,634 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "59 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:11.2.0-1ubuntu1).\n",
            "g++ set to manually installed.\n",
            "gcc is already the newest version (4:11.2.0-1ubuntu1).\n",
            "gcc set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 59 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt update\n",
        "!apt install -y gcc g++"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parallel Computing Overview\n",
        "Parallel computing refers to the process of breaking down a computational problem into smaller, independent tasks that can be executed simultaneously across multiple processors or cores. In the context of OpenMP, this involves multithreading where different sections of code are executed concurrently using threads.\n",
        "\n",
        "Benefits of Parallel Computing:\n",
        "\n",
        "Improved Performance: Tasks are executed faster as multiple computations happen simultaneously.\n",
        "Efficiency: Workload is distributed across different cores or processors.\n",
        "Scalability: Large problems can be split and processed efficiently across multiple resources.\n",
        "OpenMP Overview: OpenMP (Open Multi-Processing) is an API that supports multi-platform shared-memory parallelism in C, C++, and Fortran. It is widely used for parallelizing loops and sections of code to utilize multi-core processors.\n",
        "\n",
        "Directives: OpenMP uses #pragma directives to specify which parts of the code should be parallelized.\n",
        "Parallel Regions: Sections of code that are executed in parallel.\n",
        "Work-sharing: Dividing work among different threads."
      ],
      "metadata": {
        "id": "rMosO5-wEgwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gauss_elimination.c\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define N 4\n",
        "\n",
        "void gauss_elimination(float A[N][N], float B[N]) {\n",
        "    int i, j, k;\n",
        "    float factor;\n",
        "\n",
        "    #pragma omp parallel for private(i, j, k, factor) shared(A, B)\n",
        "    for (k = 0; k < N-1; k++) {\n",
        "        for (i = k+1; i < N; i++) {\n",
        "            factor = A[i][k] / A[k][k];\n",
        "            for (j = k; j < N; j++) {\n",
        "                A[i][j] = A[i][j] - factor * A[k][j];\n",
        "            }\n",
        "            B[i] = B[i] - factor * B[k];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float A[N][N] = {{2, -1, 1, 3},\n",
        "                     {4, 5, -2, 2},\n",
        "                     {1, 2, 3, -1},\n",
        "                     {5, 4, 3, 2}};\n",
        "    float B[N] = {8, 4, 10, 2};\n",
        "\n",
        "    // Measure time\n",
        "    clock_t start = clock();\n",
        "\n",
        "    gauss_elimination(A, B);\n",
        "\n",
        "    clock_t end = clock();\n",
        "    double time_spent = (double)(end - start) / CLOCKS_PER_SEC;\n",
        "\n",
        "    printf(\"Resultant matrix after Gaussian Elimination:\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%f \", A[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"\\nResultant vector B:\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        printf(\"%f \", B[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    printf(\"\\nExecution time: %f seconds\\n\", time_spent);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNjZCygfEV3j",
        "outputId": "3ea25ac0-90bf-4b70-8735-bd32b965a830"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gauss_elimination.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -fopenmp gauss_elimination.c -o gauss_elimination\n",
        "!time ./gauss_elimination\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBgBCxWuEnDF",
        "outputId": "818042b4-2632-4e80-c022-0d349b778954"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultant matrix after Gaussian Elimination:\n",
            "2.000000 -1.000000 1.000000 3.000000 \n",
            "0.000000 7.000000 -4.000000 -4.000000 \n",
            "0.000000 0.000000 3.928571 -1.071429 \n",
            "0.000000 0.000000 0.000000 -0.636364 \n",
            "\n",
            "Resultant vector B:\n",
            "8.000000 -12.000000 10.285714 -17.890911 \n",
            "\n",
            "Execution time: 0.000077 seconds\n",
            "\n",
            "real\t0m0.004s\n",
            "user\t0m0.001s\n",
            "sys\t0m0.000s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Theoretical Discussion\n",
        "Approach and Design of Parallel Algorithms:\n",
        "For the Gaussian Elimination algorithm, parallelism is achieved by parallelizing the elimination step (where rows are modified). OpenMP allows easy parallelization by using the #pragma omp parallel for directive.\n",
        "\n",
        "Threading and Shared Memory:\n",
        "In OpenMP, the default model is shared memory, meaning all threads share the same global address space. This simplifies communication between threads but requires proper synchronization to avoid race conditions.\n",
        "\n",
        "Load Balancing:\n",
        "In parallel algorithms, it is crucial to distribute the workload evenly across processors or threads. Poor load balancing can lead to some threads finishing earlier and remaining idle while others are still executing.\n",
        "\n"
      ],
      "metadata": {
        "id": "3Cy86b2hEran"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. LU Decomposition\n",
        "LU Decomposition is a matrix factorization technique where a matrix is decomposed into a product of two matrices, L (Lower Triangular) and U (Upper Triangular).\n",
        "\n",
        "i) Dolittle Method (LU Decomposition)\n",
        "In the Dolittle method, the lower triangular matrix L has ones on its diagonal, while the upper triangular matrix U is computed as part of the decomposition.\n",
        "\n",
        "Code for LU Decomposition (Dolittle Method)"
      ],
      "metadata": {
        "id": "nDICZv2DE7n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dolittle_lu.c\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define N 4\n",
        "\n",
        "void dolittle_lu(float A[N][N], float L[N][N], float U[N][N]) {\n",
        "    int i, j, k;\n",
        "\n",
        "    #pragma omp parallel for private(i, j, k)\n",
        "    for (i = 0; i < N; i++) {\n",
        "        // Upper Triangular Matrix U\n",
        "        for (k = i; k < N; k++) {\n",
        "            float sum = 0;\n",
        "            for (j = 0; j < i; j++) {\n",
        "                sum += L[i][j] * U[j][k];\n",
        "            }\n",
        "            U[i][k] = A[i][k] - sum;\n",
        "        }\n",
        "\n",
        "        // Lower Triangular Matrix L\n",
        "        for (k = i; k < N; k++) {\n",
        "            if (i == k) {\n",
        "                L[i][i] = 1; // Diagonal as 1\n",
        "            } else {\n",
        "                float sum = 0;\n",
        "                for (j = 0; j < i; j++) {\n",
        "                    sum += L[k][j] * U[j][i];\n",
        "                }\n",
        "                L[k][i] = (A[k][i] - sum) / U[i][i];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float A[N][N] = {{2, -1, 1, 3},\n",
        "                     {4, 5, -2, 2},\n",
        "                     {1, 2, 3, -1},\n",
        "                     {5, 4, 3, 2}};\n",
        "    float L[N][N], U[N][N];\n",
        "\n",
        "    // Measure time\n",
        "    clock_t start = clock();\n",
        "\n",
        "    dolittle_lu(A, L, U);\n",
        "\n",
        "    clock_t end = clock();\n",
        "    double time_spent = (double)(end - start) / CLOCKS_PER_SEC;\n",
        "\n",
        "    printf(\"Matrix L (Lower Triangular):\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%f \", L[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"\\nMatrix U (Upper Triangular):\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%f \", U[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"\\nExecution time: %f seconds\\n\", time_spent);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0UCzj0HE86t",
        "outputId": "bbe03487-4333-4d5b-a617-de59279d230a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dolittle_lu.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -fopenmp dolittle_lu.c -o dolittle_lu\n",
        "!time ./dolittle_lu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r19T_wWIE-Rm",
        "outputId": "b75255b4-dbb7-4576-f9cd-55e95a80eb3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix L (Lower Triangular):\n",
            "1.000000 0.000000 0.000000 0.000000 \n",
            "2.000000 1.000000 0.000000 0.000000 \n",
            "0.500000 0.357143 1.000000 0.000000 \n",
            "2.500000 0.928571 1.072727 1.000000 \n",
            "\n",
            "Matrix U (Upper Triangular):\n",
            "2.000000 -1.000000 1.000000 3.000000 \n",
            "0.000000 7.000000 -4.000000 -4.000000 \n",
            "0.000000 0.000000 3.928571 -1.071429 \n",
            "0.000000 0.000000 0.000000 -0.636364 \n",
            "\n",
            "Execution time: 0.000299 seconds\n",
            "\n",
            "real\t0m0.002s\n",
            "user\t0m0.001s\n",
            "sys\t0m0.001s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ii) Crout's Method (LU Decomposition)\n",
        "In Croutâ€™s method, the lower triangular matrix L has non-unit elements on its diagonal, and the upper triangular matrix U has ones on its diagonal.\n",
        "\n",
        "Code for LU Decomposition (Crout's Method)"
      ],
      "metadata": {
        "id": "xHM9_e8rFZqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile crout_lu.c\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define N 4\n",
        "\n",
        "void crout_lu(float A[N][N], float L[N][N], float U[N][N]) {\n",
        "    int i, j, k;\n",
        "\n",
        "    #pragma omp parallel for private(i, j, k)\n",
        "    for (i = 0; i < N; i++) {\n",
        "        // Upper Triangular Matrix U (Diagonal 1s)\n",
        "        U[i][i] = 1;\n",
        "\n",
        "        // Lower Triangular Matrix L\n",
        "        for (k = i; k < N; k++) {\n",
        "            float sum = 0;\n",
        "            for (j = 0; j < i; j++) {\n",
        "                sum += L[k][j] * U[j][i];\n",
        "            }\n",
        "            L[k][i] = A[k][i] - sum;\n",
        "        }\n",
        "\n",
        "        // Upper Triangular Matrix U\n",
        "        for (k = i+1; k < N; k++) {\n",
        "            float sum = 0;\n",
        "            for (j = 0; j < i; j++) {\n",
        "                sum += L[i][j] * U[j][k];\n",
        "            }\n",
        "            U[i][k] = (A[i][k] - sum) / L[i][i];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float A[N][N] = {{2, -1, 1, 3},\n",
        "                     {4, 5, -2, 2},\n",
        "                     {1, 2, 3, -1},\n",
        "                     {5, 4, 3, 2}};\n",
        "    float L[N][N], U[N][N];\n",
        "\n",
        "    // Measure time\n",
        "    clock_t start = clock();\n",
        "\n",
        "    crout_lu(A, L, U);\n",
        "\n",
        "    clock_t end = clock();\n",
        "    double time_spent = (double)(end - start) / CLOCKS_PER_SEC;\n",
        "\n",
        "    printf(\"Matrix L (Lower Triangular):\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%f \", L[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"\\nMatrix U (Upper Triangular):\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%f \", U[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"\\nExecution time: %f seconds\\n\", time_spent);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnbHOqkQFUAG",
        "outputId": "ad5d9f46-5b58-4d41-a964-2325c8957c7e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing crout_lu.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -fopenmp crout_lu.c -o crout_lu\n",
        "!time ./crout_lu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHP7f8Q4FbU5",
        "outputId": "35310760-c724-4f3c-f090-3a0d880c2585"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix L (Lower Triangular):\n",
            "2.000000 0.000000 0.000000 0.000000 \n",
            "4.000000 7.000000 0.000000 0.000000 \n",
            "1.000000 2.500000 3.000000 0.000000 \n",
            "5.000000 6.500000 0.500000 -5.083333 \n",
            "\n",
            "Matrix U (Upper Triangular):\n",
            "1.000000 -0.500000 0.500000 1.500000 \n",
            "0.000000 1.000000 -0.571429 -0.571429 \n",
            "0.000000 0.000000 1.000000 -0.833333 \n",
            "0.000000 0.000000 0.000000 1.000000 \n",
            "\n",
            "Execution time: 0.001915 seconds\n",
            "\n",
            "real\t0m0.004s\n",
            "user\t0m0.002s\n",
            "sys\t0m0.002s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Gauss-Seidel Method\n",
        "The Gauss-Seidel method is an iterative technique for solving a system of linear equations. It improves upon the initial guess and converges to the solution of the system.\n",
        "\n",
        "Code for Gauss-Seidel Method"
      ],
      "metadata": {
        "id": "8SsVo2D0Fh-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gauss_seidel.c\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define N 3\n",
        "#define MAX_ITER 1000\n",
        "#define TOLERANCE 0.0001\n",
        "\n",
        "void gauss_seidel(float A[N][N], float B[N], float X[N]) {\n",
        "    int i, j, k;\n",
        "    float new_X[N], sum;\n",
        "\n",
        "    for (k = 0; k < MAX_ITER; k++) {\n",
        "        int converged = 1;\n",
        "\n",
        "        #pragma omp parallel for private(i, j, sum) shared(A, B, X, new_X, converged)\n",
        "        for (i = 0; i < N; i++) {\n",
        "            sum = 0;\n",
        "            for (j = 0; j < N; j++) {\n",
        "                if (i != j) {\n",
        "                    sum += A[i][j] * X[j];\n",
        "                }\n",
        "            }\n",
        "            new_X[i] = (B[i] - sum) / A[i][i];\n",
        "\n",
        "            if (fabs(new_X[i] - X[i]) > TOLERANCE) {\n",
        "                converged = 0;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        for (i = 0; i < N; i++) {\n",
        "            X[i] = new_X[i];\n",
        "        }\n",
        "\n",
        "        if (converged) break;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float A[N][N] = {{4, 1, 2},\n",
        "                     {3, 5, 1},\n",
        "                     {1, 1, 3}};\n",
        "    float B[N] = {4, 7, 3};\n",
        "    float X[N] = {0, 0, 0};  // Initial guess\n",
        "\n",
        "    // Measure time\n",
        "    clock_t start = clock();\n",
        "\n",
        "    gauss_seidel(A, B, X);\n",
        "\n",
        "    clock_t end = clock();\n",
        "    double time_spent = (double)(end - start) / CLOCKS_PER_SEC;\n",
        "\n",
        "    printf(\"Solution Vector X:\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        printf(\"%f \", X[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    printf(\"\\nExecution time: %f seconds\\n\", time_spent);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2ZE7eP_Fhfx",
        "outputId": "58f2cd31-456d-4a64-f30c-96085373c97f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gauss_seidel.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -fopenmp gauss_seidel.c -o gauss_seidel\n",
        "!time ./gauss_seidel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzef1dAqFfRL",
        "outputId": "408a593e-cf77-4337-acf8-f4fb637d898f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution Vector X:\n",
            "0.499965 0.999962 0.499967 \n",
            "\n",
            "Execution time: 0.000338 seconds\n",
            "\n",
            "real\t0m0.003s\n",
            "user\t0m0.001s\n",
            "sys\t0m0.001s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parallelization Metrics\n",
        "After measuring the execution time, you can compute parallelization metrics such as speedup and efficiency using the following formulas:\n",
        "\n",
        "Speedup (S) = Time for Serial Execution / Time for Parallel Execution\n",
        "\n",
        "Efficiency (E) = Speedup / Number of Threads\n",
        "\n",
        "By modifying the OpenMP settings (such as setting the number of threads using omp_set_num_threads()), you can experiment with different configurations and compute these metrics."
      ],
      "metadata": {
        "id": "WjVV-976FqkE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V6kbZkpsFmsi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}